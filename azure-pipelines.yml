# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
- master

jobs:
- job: UnitTest
  pool:
    vmImage: 'vs2017-win2016'
  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.5'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-unit
    displayName: Run unit tests

- job: PostgresIntegrationTest
  pool:
    vmImage: 'win1803'
  # dependsOn: UnitTest

  steps:
  - task: Docker@1
    inputs:
      command: Run
      imageName: stellirin/postgres-windows
      qualifyImageName: false
      containerName: database
      envVars: |
        POSTGRES_USER=root
        POSTGRES_PASSWORD=password
        POSTGRES_DB=dbt
      runInBackground: true

  # the vmImage that can run docker containers ('win1803') can't use `UsePythonVersion`.
  # chocolatey suggests using 'refreshenv' here, but all subsequent commands will be lost, so don't do it
  # instead use the (undocumented?) `call RefreshEnv.cmd`: https://github.com/chocolatey/choco/issues/1461#issuecomment-348136706
  - script: |
      choco install python3 --version 3.5.4
      call RefreshEnv.cmd
      python -m pip install --upgrade pip
      python -m pip install tox
    displayName: Install python 3.5 and dependencies

  - script: |
      choco install postgresql --params '/Password:password' --params-global
      call RefreshEnv.cmd
      bash -c 'PGPASSWORD=password test/setup_db.sh'
    displayName: Run databse setup script

  - bash: ${PYTHON}\python.exe -m tox -e pywin-postgres
    env:
      PYTHON: C:\Python35
    displayName: Run integration tests

# These three are all similar except secure environment variables, which MUST be passed along to their tasks,
# but there's probably a better way to do this!
- job: SnowflakeIntegrationTest
  pool:
    vmImage: 'vs2017-win2016'
  # dependsOn: PostgresIntegrationTest

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.5'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-snowflake
    env:
      SNOWFLAKE_TEST_ACCOUNT: $(SNOWFLAKE_TEST_ACCOUNT)
      SNOWFLAKE_TEST_PASSWORD: $(SNOWFLAKE_TEST_PASSWORD)
      SNOWFLAKE_TEST_USER: $(SNOWFLAKE_TEST_USER)
      SNOWFLAKE_TEST_WAREHOUSE: $(SNOWFLAKE_TEST_WAREHOUSE)
    displayName: Run integration tests

- job: BigQueryIntegrationTest
  pool:
    vmImage: 'vs2017-win2016'
  # dependsOn: PostgresIntegrationTest

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.5'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-bigquery
    env:
      BIGQUERY_SERVICE_ACCOUNT_JSON: $(BIGQUERY_SERVICE_ACCOUNT_JSON)
    displayName: Run integration tests

- job: RedshiftIntegrationTest
  pool:
    vmImage: 'vs2017-win2016'
  # dependsOn: PostgresIntegrationTest

  steps:
  - task: UsePythonVersion@0
    inputs:
      versionSpec: '3.5'
      architecture: 'x64'

  - script: python -m pip install --upgrade pip && pip install tox
    displayName: 'Install dependencies'

  - script: python -m tox -e pywin-redshift
    env:
      REDSHIFT_TEST_DBNAME: $(REDSHIFT_TEST_DBNAME)
      SNOWFLAKE_TEST_PASS: $(SNOWFLAKE_TEST_PASS)
      SNOWFLAKE_TEST_USER: $(SNOWFLAKE_TEST_USER)
      REDSHIFT_TEST_PORT: $(REDSHIFT_TEST_PORT)
      REDSHIFT_TEST_HOST: $(REDSHIFT_TEST_HOST)
    displayName: Run integration tests
